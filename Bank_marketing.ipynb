{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be (or not) subscribed.\n",
    "\n",
    "<b>The classification goal</b> - to predict if the client will subscribe a term deposit (variable y).\n",
    "\n",
    "Number of Instances: 45211 for bank-full.csv (4521 for bank.csv)\n",
    "Number of Attributes: 16 + output attribute.\n",
    "\n",
    "<b>Input variables</b>\n",
    "\n",
    "<b>bank client data</b>\n",
    "1 - age (numeric) 2 - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\", \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\") 3 - marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed) 4 - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\") 5 - default: has credit in default? (binary: \"yes\",\"no\") 6 - balance: average yearly balance, in euros (numeric) 7 - housing: has housing loan? (binary: \"yes\",\"no\") 8 - loan: has personal loan? (binary: \"yes\",\"no\")\n",
    "\n",
    "<b>related with the last contact of the current campaign</b>\n",
    "9 - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") 10 - day: last contact day of the month (numeric) 11 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\") 12 - duration: last contact duration, in seconds (numeric)\n",
    "\n",
    "<b>other attributes</b>\n",
    "13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact) 14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted) 15 - previous: number of contacts performed before this campaign and for this client (numeric) 16 - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\n",
    "\n",
    "<b>Output variable</b>\n",
    "17 - y - has the client subscribed a term deposit? (binary: \"yes\",\"no\")\n",
    "\n",
    "Missing Attribute Values: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing <a class=\"anchor\" id=\"preproc\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age            77\n",
       "job            12\n",
       "marital         3\n",
       "education       4\n",
       "default         2\n",
       "balance      7168\n",
       "housing         2\n",
       "loan            2\n",
       "contact         3\n",
       "day            31\n",
       "month          12\n",
       "duration     1573\n",
       "campaign       48\n",
       "pdays         559\n",
       "previous       41\n",
       "poutcome        4\n",
       "y               2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank = pd.read_csv('bank-full.csv')\n",
    "bank = pd.DataFrame(bank)\n",
    "bank.isnull().sum()\n",
    "bank.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(bank):\n",
    "  #  print(\"****************************** General info ******************************\")\n",
    "    #print(bank.shape)\n",
    "    #print(bank.head())\n",
    "   # print(\"\\n>>> value counts of target variable:\\n\")\n",
    "    #print(bank['y'].value_counts())\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    bank['y'] = le.fit_transform(bank['y'])\n",
    "\n",
    "    #print(\"\\n>>> Data related to client\\n\")\n",
    "    client = bank.iloc[:,0:8]\n",
    "    labelencoder_X = LabelEncoder()\n",
    "    client['default']  = labelencoder_X.fit_transform(client['default']) \n",
    "    client['housing']  = labelencoder_X.fit_transform(client['housing']) \n",
    "    client['loan']     = labelencoder_X.fit_transform(client['loan']) \n",
    "    client = pd.get_dummies(client, drop_first=True)\n",
    "\n",
    "\n",
    "    #print(\"\\n>>> Data related to last contact\\n\")\n",
    "    last_cont = bank.iloc[:,8:12]\n",
    "    labelencoder_X = LabelEncoder()\n",
    "    last_cont['month']       = labelencoder_X.fit_transform(last_cont['month']) \n",
    "#last_cont['day'] = labelencoder_X.fit_transform(last_cont['day']) \n",
    "    last_cont = pd.get_dummies(last_cont, drop_first=True)\n",
    "\n",
    "\n",
    "    #print(\"\\n>>> others features\\n\")\n",
    "    others = bank.iloc[:,12:16]\n",
    "    #others['poutcome'].replace(['unknown', 'failure', 'success','other'], [1,2,3,4], inplace  = True)\n",
    "    others = pd.get_dummies(others, drop_first=True)\n",
    "    #print(\"\\n>>> final form of data\\n\")\n",
    "    final= pd.concat([client, last_cont,others], axis = 1)\n",
    "    final.shape\n",
    "    final = pd.concat([final,bank['y']],axis = 1)\n",
    "    #print(final.head())\n",
    "\n",
    "    #split data\n",
    "    X=final.drop(\"y\",axis=1)\n",
    "    y = final['y']\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    #standarization\n",
    "    sc_X = StandardScaler()\n",
    "    X_train = sc_X.fit_transform(X_train)\n",
    "    X_test = sc_X.transform(X_test)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test, final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>...</th>\n",
       "      <th>duration</th>\n",
       "      <th>contact_telephone</th>\n",
       "      <th>contact_unknown</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>2143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1506</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  default  balance  housing  loan  job_blue-collar  job_entrepreneur  \\\n",
       "0   58        0     2143        1     0                0                 0   \n",
       "1   44        0       29        1     0                0                 0   \n",
       "2   33        0        2        1     1                0                 1   \n",
       "3   47        0     1506        1     0                1                 0   \n",
       "4   33        0        1        0     0                0                 0   \n",
       "\n",
       "   job_housemaid  job_management  job_retired  ...  duration  \\\n",
       "0              0               1            0  ...       261   \n",
       "1              0               0            0  ...       151   \n",
       "2              0               0            0  ...        76   \n",
       "3              0               0            0  ...        92   \n",
       "4              0               0            0  ...       198   \n",
       "\n",
       "   contact_telephone  contact_unknown  campaign  pdays  previous  \\\n",
       "0                  0                1         1     -1         0   \n",
       "1                  0                1         1     -1         0   \n",
       "2                  0                1         1     -1         0   \n",
       "3                  0                1         1     -1         0   \n",
       "4                  0                1         1     -1         0   \n",
       "\n",
       "   poutcome_other  poutcome_success  poutcome_unknown  y  \n",
       "0               0                 0                 1  0  \n",
       "1               0                 0                 1  0  \n",
       "2               0                 0                 1  0  \n",
       "3               0                 0                 1  0  \n",
       "4               0                 0                 1  0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test, final = prepareData(bank)\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.3322783549363608\n",
      "10 0.5118244164630351\n",
      "15 0.6746462288836544\n",
      "20 0.820215585695255\n",
      "25 0.934320116301499\n",
      "30 0.9929835288564259\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,7):\n",
    "    pca = PCA(n_components=i*5)\n",
    "    pca.fit(X_train)\n",
    "    print(i*5, pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_thresh_and_f1(clf, X_valid, y_valid):\n",
    "    best_f1=0\n",
    "    best_thresh=0\n",
    "    thresh = 0.05\n",
    "    prob = clf.predict_proba(X_valid)\n",
    "    while thresh < 1:\n",
    "        label = (prob[:,0] < thresh).astype(np.int)\n",
    "        f1 = f1_score(y_valid,label)\n",
    "#         print(f1)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thresh = thresh\n",
    "        thresh += 0.05\n",
    "    return best_thresh, best_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 gini auto 0.5473684210526316\n",
      "2 gini None 0.5205171444631816\n",
      "2 entropy auto 0.5207152202354993\n",
      "2 entropy None 0.5105527638190955\n",
      "3 gini auto 0.5456204379562044\n",
      "3 gini None 0.5476824720298349\n",
      "3 entropy auto 0.5332775219757221\n",
      "3 entropy None 0.5313693398799781\n",
      "4 gini auto 0.5683453237410072\n",
      "4 gini None 0.5572666025024061\n",
      "4 entropy auto 0.5553235908141961\n",
      "4 entropy None 0.5258166491043204\n",
      "5 gini auto 0.5680119581464873\n",
      "5 gini None 0.5743645213628987\n",
      "5 entropy auto 0.5514600287218765\n",
      "5 entropy None 0.534617700180614\n",
      "6 gini auto 0.5824390243902439\n",
      "6 gini None 0.5771144278606966\n",
      "6 entropy auto 0.5683918669131238\n",
      "6 entropy None 0.5551684088269455\n",
      "7 gini auto 0.580886278697277\n",
      "7 gini None 0.5793871866295265\n",
      "7 entropy auto 0.5798319327731093\n",
      "7 entropy None 0.5839487936976858\n",
      "8 gini auto 0.584353379457158\n",
      "8 gini None 0.5884177869700103\n",
      "8 entropy auto 0.5825446898002102\n",
      "8 entropy None 0.5983739837398374\n",
      "9 gini auto 0.5901132852729145\n",
      "9 gini None 0.5868320610687022\n",
      "9 entropy auto 0.5850202429149798\n",
      "9 entropy None 0.5964149918522542\n",
      "10 gini auto 0.5907000510986204\n",
      "10 gini None 0.5912882298424467\n",
      "10 entropy auto 0.5844930417495029\n",
      "10 entropy None 0.5991902834008096\n",
      "11 gini auto 0.5916134913400183\n",
      "11 gini None 0.5977757182576459\n",
      "11 entropy auto 0.5905861456483126\n",
      "11 entropy None 0.6094339622641509\n",
      "12 gini auto 0.5908639523336643\n",
      "12 gini None 0.5991754466330738\n",
      "12 entropy auto 0.5989252564728871\n",
      "12 entropy None 0.6016042780748663\n",
      "13 gini auto 0.596279537456008\n",
      "13 gini None 0.5976789168278531\n",
      "13 entropy auto 0.5985330073349634\n",
      "13 entropy None 0.6072672971627675\n",
      "14 gini auto 0.5946745562130178\n",
      "14 gini None 0.603974793989336\n",
      "14 entropy auto 0.6022232962783953\n",
      "14 entropy None 0.6056056056056057\n",
      "15 gini auto 0.5970443349753695\n",
      "15 gini None 0.6038095238095238\n",
      "15 entropy auto 0.5997130559540889\n",
      "15 entropy None 0.6053026513256629\n",
      "16 gini auto 0.59375\n",
      "16 gini None 0.6049618320610688\n",
      "16 entropy auto 0.5981757081132982\n",
      "16 entropy None 0.6102012166588676\n",
      "17 gini auto 0.6015549076773566\n",
      "17 gini None 0.6035950804162724\n",
      "17 entropy auto 0.5927360774818402\n",
      "17 entropy None 0.6080449017773619\n",
      "18 gini auto 0.6011560693641619\n",
      "18 gini None 0.6011342155009453\n",
      "18 entropy auto 0.5967488201363399\n",
      "18 entropy None 0.6066303809995053\n",
      "19 gini auto 0.592911877394636\n",
      "19 gini None 0.5987856141989725\n",
      "19 entropy auto 0.6007568590350048\n",
      "19 entropy None 0.6037084950409659\n"
     ]
    }
   ],
   "source": [
    "Best_model=None\n",
    "Best_score=0\n",
    "Best_thresh = 0\n",
    "for n in range(2,20):\n",
    "    for c in [\"gini\",\"entropy\"]:\n",
    "        for mf in [\"auto\",None]:\n",
    "            clf = RandomForestClassifier(max_depth=n, criterion=c, max_features=mf,n_jobs=2)\n",
    "            clf.fit(X_train, y_train)\n",
    "            thresh, score = find_thresh_and_f1(clf, X_valid, y_valid)\n",
    "            print(n, c, mf, score)\n",
    "            if score>Best_score:\n",
    "                Best_model=clf\n",
    "                Best_score= score\n",
    "                Best_thresh = thresh\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best forest RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='entropy', max_depth=16, max_features=None,\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=2,\n",
      "                       oob_score=False, random_state=None, verbose=0,\n",
      "                       warm_start=False) f1 0.6014652014652014\n"
     ]
    }
   ],
   "source": [
    "y_pred = Best_model.predict_proba(X_test)\n",
    "label = (y_pred[:,0] < Best_thresh).astype(np.int)\n",
    "f1_forest = f1_score(y_test,label)\n",
    "thresh_forest = Best_thresh\n",
    "best_forest = Best_model \n",
    "print(\"best forest\",best_forest,'f1', f1_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(estimator=best_forest, X=X_train, y=y_train, \n",
    "                                                        train_sizes=np.linspace(0.1, 1.0, 10), \n",
    "                                                        cv=10, n_jobs=1,scoring=\"f1\")\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1) \n",
    "train_std = np.std(train_scores, axis=1) \n",
    "test_mean = np.mean(test_scores, axis=1) \n",
    "test_std = np.std(test_scores, axis=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_sizes, train_mean,color='blue', marker='o', markersize=5, label='training accuracy')\n",
    "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std,alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, test_mean, color='green', linestyle='--', marker='s', markersize=5, label='validation accuracy')\n",
    "plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('f1_score')\n",
    "plt.legend(loc='lower right') \n",
    "plt.ylim([-0.8, 1.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 0.5283218634197988\n",
      "0.001 0.5542935029532032\n",
      "0.01 0.5547119249665029\n",
      "0.1 0.5538781884435191\n",
      "1.0 0.554054054054054\n",
      "10.0 0.554054054054054\n",
      "100.0 0.554054054054054\n"
     ]
    }
   ],
   "source": [
    "Best_model=None\n",
    "Best_score=0\n",
    "Best_thresh = 0\n",
    "c=0.0001\n",
    "while c < 1000:\n",
    "        clf = LogisticRegression(C=c)\n",
    "        clf.fit(X_train, y_train)\n",
    "        thresh, score = find_thresh_and_f1(clf, X_valid, y_valid)\n",
    "        print(c,score)\n",
    "        if score>Best_score:\n",
    "            Best_model=clf\n",
    "            Best_score= score\n",
    "            Best_thresh = thresh\n",
    "        c *= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best logreg LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) f1 0.5302390998593529\n"
     ]
    }
   ],
   "source": [
    "y_pred = Best_model.predict_proba(X_test)\n",
    "label = (y_pred[:,0] < Best_thresh).astype(np.int)\n",
    "f1_logreg = f1_score(y_test,label)\n",
    "best_logreg = Best_model \n",
    "thresh_logreg= Best_thresh\n",
    "print(\"best logreg\",best_logreg,'f1', f1_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 gini 0.001 0.4349295774647887\n",
      "1 gini 0.01 0.468677494199536\n",
      "1 gini 0.1 0.5330798479087452\n",
      "1 gini 0.2 0.3654485049833887\n",
      "1 gini 0.5 0.43351268255188313\n",
      "1 gini 1 0.4618834080717489\n",
      "1 gini 10 0.21404764843846438\n",
      "1 entropy 0.001 0.43145821955215724\n",
      "1 entropy 0.01 0.4797507788161994\n",
      "1 entropy 0.1 0.5329272934906738\n",
      "1 entropy 0.2 0.37438423645320196\n",
      "1 entropy 0.5 0.42989214175654855\n",
      "1 entropy 1 0.45937961595273263\n",
      "1 entropy 10 0.21404764843846438\n",
      "2 gini 0.001 0.48022079116835326\n",
      "2 gini 0.01 0.5148690634709278\n",
      "2 gini 0.1 0.5570776255707762\n",
      "2 gini 0.2 0.4914625092798813\n",
      "2 gini 0.5 0.5151301900070373\n",
      "2 gini 1 0.5244565217391305\n",
      "2 gini 10 0.21404764843846438\n",
      "2 entropy 0.001 0.4735692442114461\n",
      "2 entropy 0.01 0.5084306095979246\n",
      "2 entropy 0.1 0.5606118546845124\n",
      "2 entropy 0.2 0.4900074019245004\n",
      "2 entropy 0.5 0.4957627118644068\n",
      "2 entropy 1 0.5169435215946844\n",
      "2 entropy 10 0.21404764843846438\n",
      "3 gini 0.001 0.5435435435435436\n",
      "3 gini 0.01 0.556237218813906\n",
      "3 gini 0.1 0.5701184562476117\n",
      "3 gini 0.2 0.5113960113960113\n",
      "3 gini 0.5 0.5414438502673797\n",
      "3 gini 1 0.5179856115107914\n",
      "3 gini 10 0.21465709333993563\n",
      "3 entropy 0.001 0.5225603357817418\n",
      "3 entropy 0.01 0.5348214285714287\n",
      "3 entropy 0.1 0.5748273215656178\n",
      "3 entropy 0.2 0.5085470085470085\n",
      "3 entropy 0.5 0.5257378174330817\n",
      "3 entropy 1 0.5189542483660131\n",
      "3 entropy 10 0.5213270142180094\n",
      "4 gini 0.001 0.5663542180562406\n",
      "4 gini 0.01 0.5661896243291592\n",
      "4 gini 0.1 0.5821371610845295\n",
      "4 gini 0.2 0.521497919556172\n",
      "4 gini 0.5 0.5155732273028495\n",
      "4 gini 1 0.5100250626566415\n",
      "4 gini 10 0.21427687739700607\n",
      "4 entropy 0.001 0.5311443746982135\n",
      "4 entropy 0.01 0.5538325210456357\n",
      "4 entropy 0.1 0.5759036144578313\n",
      "4 entropy 0.2 0.5090655509065551\n",
      "4 entropy 0.5 0.5063122923588039\n",
      "4 entropy 1 0.5016329196603527\n",
      "4 entropy 10 0.5245018847603661\n",
      "5 gini 0.001 0.5662831415707853\n",
      "5 gini 0.01 0.5751898734177214\n",
      "5 gini 0.1 0.5833333333333334\n",
      "5 gini 0.2 0.5335138794854434\n",
      "5 gini 0.5 0.48298429319371733\n",
      "5 gini 1 0.48218829516539446\n",
      "5 gini 10 0.21404764843846438\n",
      "5 entropy 0.001 0.5402797877472262\n",
      "5 entropy 0.01 0.5694783032666992\n",
      "5 entropy 0.1 0.5844863731656185\n",
      "5 entropy 0.2 0.5151719487525287\n",
      "5 entropy 0.5 0.4915474642392718\n",
      "5 entropy 1 0.5047199496538703\n",
      "5 entropy 10 0.36319824753559693\n",
      "6 gini 0.001 0.5702930948832589\n",
      "6 gini 0.01 0.5820244328097731\n",
      "6 gini 0.1 0.593065693430657\n",
      "6 gini 0.2 0.48308525033829497\n",
      "6 gini 0.5 0.4579439252336448\n",
      "6 gini 1 0.4661944623309723\n",
      "6 gini 10 0.21404764843846438\n",
      "6 entropy 0.001 0.5473776994270604\n",
      "6 entropy 0.01 0.5760917512130569\n",
      "6 entropy 0.1 0.5690983235160852\n",
      "6 entropy 0.2 0.48415374241402565\n",
      "6 entropy 0.5 0.4571045576407507\n",
      "6 entropy 1 0.4672897196261682\n",
      "6 entropy 10 0.3025568181818181\n",
      "7 gini 0.001 0.5704793545325106\n",
      "7 gini 0.01 0.5844454670961803\n",
      "7 gini 0.1 0.5497251374312844\n",
      "7 gini 0.2 0.5151515151515151\n",
      "7 gini 0.5 0.48854217454900045\n",
      "7 gini 1 0.5009920634920635\n",
      "7 gini 10 0.21607278241091737\n",
      "7 entropy 0.001 0.5657289002557546\n",
      "7 entropy 0.01 0.580136626379401\n",
      "7 entropy 0.1 0.5516883116883117\n",
      "7 entropy 0.2 0.48648648648648646\n",
      "7 entropy 0.5 0.5216494845360825\n",
      "7 entropy 1 0.520973588814086\n",
      "7 entropy 10 0.3026621404323745\n",
      "8 gini 0.001 0.569672131147541\n",
      "8 gini 0.01 0.5654761904761905\n",
      "8 gini 0.1 0.526377491207503\n",
      "8 gini 0.2 0.5150115473441109\n",
      "8 gini 0.5 0.5137130801687763\n",
      "8 gini 1 0.5335446381405177\n",
      "8 gini 10 0.21404764843846438\n",
      "8 entropy 0.001 0.5758176412289395\n",
      "8 entropy 0.01 0.5777543489720611\n",
      "8 entropy 0.1 0.5366108786610879\n",
      "8 entropy 0.2 0.5206738131699847\n",
      "8 entropy 0.5 0.5484949832775919\n",
      "8 entropy 1 0.5249597423510467\n",
      "8 entropy 10 0.2978798586572438\n",
      "9 gini 0.001 0.5544871794871794\n",
      "9 gini 0.01 0.5667752442996743\n",
      "9 gini 0.1 0.5318230852211435\n",
      "9 gini 0.2 0.5532994923857869\n",
      "9 gini 0.5 0.5574406204556471\n",
      "9 gini 1 0.5503802281368821\n",
      "9 gini 10 0.46219686162624823\n",
      "9 entropy 0.001 0.5637651821862347\n",
      "9 entropy 0.01 0.5504201680672269\n",
      "9 entropy 0.1 0.5552325581395349\n",
      "9 entropy 0.2 0.5453569511540526\n",
      "9 entropy 0.5 0.5539130434782609\n",
      "9 entropy 1 0.5439847836424156\n",
      "9 entropy 10 0.42295081967213116\n",
      "10 gini 0.001 0.53028692879915\n",
      "10 gini 0.01 0.540948275862069\n",
      "10 gini 0.1 0.5452793834296724\n",
      "10 gini 0.2 0.5613346418056919\n",
      "10 gini 0.5 0.5675675675675675\n",
      "10 gini 1 0.556829035339064\n",
      "10 gini 10 0.501892505677517\n",
      "10 entropy 0.001 0.5409326424870466\n",
      "10 entropy 0.01 0.5327916424840395\n",
      "10 entropy 0.1 0.5673549655850542\n",
      "10 entropy 0.2 0.577472236911687\n",
      "10 entropy 0.5 0.5811567164179106\n",
      "10 entropy 1 0.5540599218410769\n",
      "10 entropy 10 0.32726528942524036\n",
      "11 gini 0.001 0.5209988649262202\n",
      "11 gini 0.01 0.5364274150026983\n",
      "11 gini 0.1 0.5745798319327732\n",
      "11 gini 0.2 0.5711371749107599\n",
      "11 gini 0.5 0.5740922473012757\n",
      "11 gini 1 0.568788501026694\n",
      "11 gini 10 0.2553626149131767\n",
      "11 entropy 0.001 0.5273972602739726\n",
      "11 entropy 0.01 0.5427394438722966\n",
      "11 entropy 0.1 0.5506294471811712\n",
      "11 entropy 0.2 0.5606060606060607\n",
      "11 entropy 0.5 0.5741225772655841\n",
      "11 entropy 1 0.5760722347629798\n",
      "11 entropy 10 0.49377865094957435\n",
      "12 gini 0.001 0.5191846522781773\n",
      "12 gini 0.01 0.5478510028653295\n",
      "12 gini 0.1 0.5640436530729467\n",
      "12 gini 0.2 0.5666486778197517\n",
      "12 gini 0.5 0.5596481583287519\n",
      "12 gini 1 0.5626262626262627\n",
      "12 gini 10 0.528034839412085\n",
      "12 entropy 0.001 0.5205479452054795\n",
      "12 entropy 0.01 0.535671100362757\n",
      "12 entropy 0.1 0.5295950155763239\n",
      "12 entropy 0.2 0.5558840922531048\n",
      "12 entropy 0.5 0.5603201829616924\n",
      "12 entropy 1 0.5633210719915923\n",
      "12 entropy 10 0.5224586288416077\n",
      "13 gini 0.001 0.5034883720930233\n",
      "13 gini 0.01 0.5476718403547672\n",
      "13 gini 0.1 0.5680473372781065\n",
      "13 gini 0.2 0.542433234421365\n",
      "13 gini 0.5 0.5623880597014925\n",
      "13 gini 1 0.5656455142231948\n",
      "13 gini 10 0.24721311475409838\n",
      "13 entropy 0.001 0.5058962264150944\n",
      "13 entropy 0.01 0.5477784540474742\n",
      "13 entropy 0.1 0.52375\n",
      "13 entropy 0.2 0.5227418321588725\n",
      "13 entropy 0.5 0.5347394540942928\n",
      "13 entropy 1 0.5652173913043479\n",
      "13 entropy 10 0.33250620347394544\n",
      "14 gini 0.001 0.5079178885630499\n",
      "14 gini 0.01 0.5398550724637681\n",
      "14 gini 0.1 0.5428226779252111\n",
      "14 gini 0.2 0.5254854368932038\n",
      "14 gini 0.5 0.5389809699201964\n",
      "14 gini 1 0.5517627308337996\n",
      "14 gini 10 0.2635658914728682\n",
      "14 entropy 0.001 0.5303668069753459\n",
      "14 entropy 0.01 0.5265127885215222\n",
      "14 entropy 0.1 0.5295989815404201\n",
      "14 entropy 0.2 0.5082290980908493\n",
      "14 entropy 0.5 0.5267224726336124\n",
      "14 entropy 1 0.5388724035608308\n",
      "14 entropy 10 0.4495412844036697\n",
      "15 gini 0.001 0.506776664702416\n",
      "15 gini 0.01 0.5631419939577039\n",
      "15 gini 0.1 0.5415884928080049\n",
      "15 gini 0.2 0.5340838023764852\n",
      "15 gini 0.5 0.5433117265763112\n",
      "15 gini 1 0.5552342394447657\n",
      "15 gini 10 0.42126789366053174\n",
      "15 entropy 0.001 0.5138479670005892\n",
      "15 entropy 0.01 0.5354430379746836\n",
      "15 entropy 0.1 0.4953764861294584\n",
      "15 entropy 0.2 0.5036160420775806\n",
      "15 entropy 0.5 0.5245258338783519\n",
      "15 entropy 1 0.5481120584652863\n",
      "15 entropy 10 0.3784153005464481\n",
      "16 gini 0.001 0.5017064846416383\n",
      "16 gini 0.01 0.5440289505428227\n",
      "16 gini 0.1 0.5258566978193147\n",
      "16 gini 0.2 0.5381165919282511\n",
      "16 gini 0.5 0.5135313531353136\n",
      "16 gini 1 0.5454545454545454\n",
      "16 gini 10 0.3044496487119438\n",
      "16 entropy 0.001 0.5142531356898519\n",
      "16 entropy 0.01 0.5301204819277108\n",
      "16 entropy 0.1 0.528476821192053\n",
      "16 entropy 0.2 0.46142958244869076\n",
      "16 entropy 0.5 0.49313186813186816\n",
      "16 entropy 1 0.5219072164948454\n",
      "16 entropy 10 0.34567901234567905\n",
      "17 gini 0.001 0.46990064289888955\n",
      "17 gini 0.01 0.539424280350438\n",
      "17 gini 0.1 0.5474083438685208\n",
      "17 gini 0.2 0.5186119873817036\n",
      "17 gini 0.5 0.5168682367918523\n",
      "17 gini 1 0.5439127801332526\n",
      "17 gini 10 0.3953488372093023\n",
      "17 entropy 0.001 0.504524886877828\n",
      "17 entropy 0.01 0.5070063694267517\n",
      "17 entropy 0.1 0.48915989159891593\n",
      "17 entropy 0.2 0.49345279117849766\n",
      "17 entropy 0.5 0.4818435754189944\n",
      "17 entropy 1 0.5387076135636596\n",
      "17 entropy 10 0.4362801377726751\n",
      "18 gini 0.001 0.49710982658959535\n",
      "18 gini 0.01 0.5221736414740786\n",
      "18 gini 0.1 0.5361216730038022\n",
      "18 gini 0.2 0.5510331872260489\n",
      "18 gini 0.5 0.5197368421052632\n",
      "18 gini 1 0.5356924954240391\n",
      "18 gini 10 0.36654366543665434\n",
      "18 entropy 0.001 0.4900737379466818\n",
      "18 entropy 0.01 0.5326695706285003\n",
      "18 entropy 0.1 0.4608819345661452\n",
      "18 entropy 0.2 0.46910112359550565\n",
      "18 entropy 0.5 0.49134948096885817\n",
      "18 entropy 1 0.5355048859934852\n",
      "18 entropy 10 0.4067919075144509\n",
      "19 gini 0.001 0.4807121661721069\n",
      "19 gini 0.01 0.5027726432532348\n",
      "19 gini 0.1 0.5170603674540681\n",
      "19 gini 0.2 0.5238709677419354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 gini 0.5 0.5218525766470973\n",
      "19 gini 1 0.5463474524248005\n",
      "19 gini 10 0.4219948849104859\n",
      "19 entropy 0.001 0.4997087944088527\n",
      "19 entropy 0.01 0.4993954050785973\n",
      "19 entropy 0.1 0.4394366197183099\n",
      "19 entropy 0.2 0.48109965635738833\n",
      "19 entropy 0.5 0.47790055248618785\n",
      "19 entropy 1 0.5227568270481144\n",
      "19 entropy 10 0.4479850046860356\n"
     ]
    }
   ],
   "source": [
    "Best_model=None\n",
    "Best_score=0\n",
    "Best_thresh = 0\n",
    "for n in range(1,20):\n",
    "    for c in [\"gini\",\"entropy\"]:\n",
    "        for lr in [0.001,0.01, 0.1, 0.2, 0.5,1,10]:\n",
    "            tree = DecisionTreeClassifier(criterion=c, \n",
    "                              max_depth=n,\n",
    "                              random_state=0)\n",
    "            clf = AdaBoostClassifier(base_estimator=tree,\n",
    "                         n_estimators=100, \n",
    "                         learning_rate=lr,\n",
    "                         random_state=0)\n",
    "            clf.fit(X_train, y_train)\n",
    "            thresh, score = find_thresh_and_auc(clf, X_valid, y_valid)\n",
    "            print(n, c, lr, score)\n",
    "            if score>Best_score:\n",
    "                Best_model=clf\n",
    "                Best_score= score\n",
    "                Best_thresh = thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best adab KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform') f1 0.5068039720485472\n"
     ]
    }
   ],
   "source": [
    "y_pred = Best_model.predict_proba(X_test)\n",
    "label = (y_pred[:,0] < Best_thresh).astype(np.int)\n",
    "f1_adab = f1_score(y_test,label)\n",
    "best_adab = Best_model \n",
    "print(\"best adab\",best_adab,'f1', f1_adab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2561\n",
       "1     331\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_small = pd.read_csv('bank.csv')\n",
    "bank_small = pd.DataFrame(bank_small)\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test,final = prepareData(bank_small)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 98 candidates, totalling 490 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   57.4s\n",
      "[Parallel(n_jobs=4)]: Done 490 out of 490 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=True, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=4,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [100, 10, 1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf', 'poly']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.001,0.01,0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [100,10,1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf','poly']}  \n",
    "grid = GridSearchCV(SVC(probability=True), param_grid,n_jobs=4, refit = True, verbose = 3,scoring ='f1') \n",
    "grid.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'gamma': 1, 'kernel': 'poly'}\n",
      "SVC(C=0.01, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=1, kernel='poly',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(grid.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svm1 = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =best_svm1.predict(X_test)\n",
    "#label = (y_pred[:,0] < Best_thresh).astype(np.int)\n",
    "f1_svm1 = f1_score(y_test,y_pred)\n",
    "print(\"best svm\",best_svm1,'f1', f1_svm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.01, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=1, kernel='poly',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(C=0.01, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma=1, kernel='poly',\n",
    "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
    "    verbose=False)\n",
    "svm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best svm SVC(C=0.01, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=1, kernel='poly',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False) f1 0.4621893178212586\n"
     ]
    }
   ],
   "source": [
    "bestsvm = svm\n",
    "y_pred =bestsvm.predict(X_test)\n",
    "f1svm = f1_score(y_test,y_pred)\n",
    "print(\"best svm\",bestsvm,'f1', f1svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-0c2eba01ec50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'minkowski'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mthresh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_thresh_and_f1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;31m#print(p,k,score)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mBest_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-3e64132265d1>\u001b[0m in \u001b[0;36mfind_thresh_and_f1\u001b[1;34m(clf, X_valid, y_valid)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mbest_thresh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mthresh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mthresh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programy\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programy\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    661\u001b[0m                 delayed_query(\n\u001b[0;32m    662\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[1;32m--> 663\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    664\u001b[0m             )\n\u001b[0;32m    665\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programy\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programy\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programy\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programy\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programy\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programy\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programy\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programy\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[1;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m     \"\"\"\n\u001b[1;32m--> 490\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Best_model=None\n",
    "Best_score=0\n",
    "Best_thresh = 0\n",
    "for p in range(1,2):\n",
    "    for k in range(2,20):\n",
    "        clf = KNeighborsClassifier(n_neighbors=k, p=p,metric='minkowski')\n",
    "        clf.fit(X_train, y_train)\n",
    "        thresh, score = find_thresh_and_f1(clf, X_valid, y_valid)\n",
    "        #print(p,k,score)\n",
    "        if score>Best_score:\n",
    "            Best_model=clf\n",
    "            Best_score= score\n",
    "            Best_thresh = thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best KNN KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform') f1 0.5046869141357331\n"
     ]
    }
   ],
   "source": [
    "y_pred = Best_model.predict_proba(X_test)\n",
    "label = (y_pred[:,0] < Best_thresh).astype(np.int)\n",
    "f1_knn = f1_score(y_test,label)\n",
    "best_knn = Best_model \n",
    "print(\"best KNN\",best_knn,'f1', f1_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(150,150,150,100,50), max_iter=1000,activation = 'relu',solver='adam',random_state=1)\n",
    "mlp.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.480 (+/-0.041) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.481 (+/-0.032) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.483 (+/-0.037) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.486 (+/-0.050) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.478 (+/-0.039) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.476 (+/-0.036) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.482 (+/-0.048) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.483 (+/-0.030) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.471 (+/-0.050) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.494 (+/-0.026) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.473 (+/-0.030) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.500 (+/-0.039) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.482 (+/-0.036) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.504 (+/-0.046) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.478 (+/-0.036) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.493 (+/-0.041) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.479 (+/-0.037) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.494 (+/-0.046) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.477 (+/-0.025) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.502 (+/-0.019) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.471 (+/-0.027) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.500 (+/-0.042) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.472 (+/-0.037) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.497 (+/-0.038) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.486 (+/-0.063) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.474 (+/-0.007) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.498 (+/-0.032) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.474 (+/-0.020) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.485 (+/-0.040) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.469 (+/-0.023) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.481 (+/-0.055) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.456 (+/-0.034) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.461 (+/-0.031) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.496 (+/-0.044) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.460 (+/-0.046) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.489 (+/-0.010) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.476 (+/-0.042) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.463 (+/-0.033) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.485 (+/-0.028) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.471 (+/-0.045) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.494 (+/-0.036) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.474 (+/-0.043) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.478 (+/-0.030) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.484 (+/-0.023) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.462 (+/-0.047) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.502 (+/-0.044) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.457 (+/-0.043) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.491 (+/-0.032) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(max_iter=100)\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-2, cv=5,scoring='f1')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best parameters found:\\n', clf.best_params_)\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best adab MLPClassifier(activation='tanh', alpha=0.05, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(50, 50, 50), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False) f1 0.47584033613445376\n"
     ]
    }
   ],
   "source": [
    "best_adab =clf.best_estimator_\n",
    "y_pred = best_adab.predict(X_test)\n",
    "f1_adab = f1_score(y_test,y_pred)\n",
    "best_adab =clf.best_estimator_\n",
    "print(\"best adab\",best_adab,'f1', f1_adab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE, UNDERSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2561\n",
       "1     331\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_small = pd.read_csv('bank.csv')\n",
    "bank_small = pd.DataFrame(bank_small)\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test,final = prepareData(bank_small)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overSMOTE(X_train,y_train,samp_strat):\n",
    "    sm = SMOTE(sampling_strategy=samp_strat,k_neighbors=5,n_jobs=2)\n",
    "    X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "    y_train.value_counts()\n",
    "    return X_train,y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(X_train,y_train,columns):\n",
    "    df_y_train = pd.DataFrame(y_train,columns=['y'])\n",
    "    df_X_train = pd.DataFrame(data=X_train,columns=columns)\n",
    "    df_X_train.reset_index(drop=True, inplace=True)\n",
    "    df_y_train.reset_index(drop=True, inplace=True)\n",
    "    X= pd.concat([df_X_train, df_y_train], axis = 1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resamp(X,n_samples):\n",
    "    not_subscribed = X[X.y==0]\n",
    "    subscribed = X[X.y==1]\n",
    "\n",
    "    not_subscribed_undersampled = resample(not_subscribed,\n",
    "                              replace=False, \n",
    "                              n_samples=n_samples, \n",
    "                              random_state=1) \n",
    "    not_subscribed_undersampled.reset_index(drop=True, inplace=True)\n",
    "    subscribed.reset_index(drop=True, inplace=True)\n",
    "    undersampled = pd.concat([not_subscribed_undersampled,subscribed], axis = 0)\n",
    "    print(undersampled.y.value_counts())\n",
    "    y_train = undersampled.y\n",
    "    X_train = undersampled.drop('y', axis=1)\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2561\n",
       "1    2304\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,y_train = overSMOTE(X_train,y_train,0.9)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 10 0.024691358024691357\n",
      "0.001 10 0.43434343434343436\n",
      "0.001 1 0.2688679245283019\n",
      "0.001 1 0.3781094527363184\n",
      "0.001 0.1 0.4651162790697675\n",
      "0.001 0.1 0.4636363636363636\n",
      "0.001 0.01 0.46153846153846156\n",
      "0.001 0.01 0.3894736842105263\n",
      "0.001 0.001 0.4622641509433962\n",
      "0.001 0.001 0.3805309734513274\n",
      "0.001 0.0001 0.4537037037037037\n",
      "0.001 0.0001 0.1945137157107232\n",
      "0.01 10 0.20301783264746226\n",
      "0.01 10 0.4153005464480874\n",
      "0.01 1 0.2878787878787879\n",
      "0.01 1 0.3504273504273504\n",
      "0.01 0.1 0.48039215686274517\n",
      "0.01 0.1 0.5276073619631901\n",
      "0.01 0.01 0.4811320754716981\n",
      "0.01 0.01 0.38918918918918916\n",
      "0.01 0.001 0.4585365853658537\n",
      "0.01 0.001 0.3247863247863248\n",
      "0.01 0.0001 0.46009389671361506\n",
      "0.01 0.0001 0.1945137157107232\n",
      "0.1 10 0.20470262793914246\n",
      "0.1 10 0.41304347826086957\n",
      "0.1 1 0.2835820895522388\n",
      "0.1 1 0.4093567251461988\n",
      "0.1 0.1 0.475609756097561\n",
      "0.1 0.1 0.4375\n",
      "0.1 0.01 0.5308056872037914\n",
      "0.1 0.01 0.4129032258064516\n",
      "0.1 0.001 0.504950495049505\n",
      "0.1 0.001 0.38095238095238093\n",
      "0.1 0.0001 0.4585365853658537\n",
      "0.1 0.0001 0.35114503816793896\n",
      "1 10 0.19919246298788695\n",
      "1 10 0.4153005464480874\n",
      "1 1 0.2565130260521042\n",
      "1 1 0.43434343434343436\n",
      "1 0.1 0.42512077294685996\n",
      "1 0.1 0.37762237762237766\n",
      "1 0.01 0.5145631067961165\n",
      "1 0.01 0.4615384615384616\n",
      "1 0.001 0.5280898876404494\n",
      "1 0.001 0.39361702127659576\n",
      "1 0.0001 0.5123152709359605\n",
      "1 0.0001 0.34375\n",
      "10 10 0.20933521923620932\n",
      "10 10 0.4153005464480874\n",
      "10 1 0.26195426195426197\n",
      "10 1 0.4153005464480874\n",
      "10 0.1 0.41304347826086957\n",
      "10 0.1 0.3489361702127659\n",
      "10 0.01 0.4974093264248704\n",
      "10 0.01 0.5276073619631901\n",
      "10 0.001 0.53551912568306\n",
      "10 0.001 0.38918918918918916\n",
      "10 0.0001 0.527363184079602\n",
      "10 0.0001 0.4119601328903654\n",
      "100 10 0.20273972602739726\n",
      "100 10 0.4153005464480874\n",
      "100 1 0.25250501002004005\n",
      "100 1 0.4153005464480874\n",
      "100 0.1 0.40217391304347827\n",
      "100 0.1 0.4023668639053255\n",
      "100 0.01 0.4034334763948498\n",
      "100 0.01 0.4375\n",
      "100 0.001 0.5138888888888888\n",
      "100 0.001 0.4129032258064516\n",
      "100 0.0001 0.5368421052631579\n",
      "100 0.0001 0.3915343915343915\n",
      "1000 10 0.2066957787481805\n",
      "1000 10 0.4153005464480874\n",
      "1000 1 0.26582278481012656\n",
      "1000 1 0.4153005464480874\n",
      "1000 0.1 0.3846153846153846\n",
      "1000 0.1 0.43434343434343436\n",
      "1000 0.01 0.37499999999999994\n",
      "1000 0.01 0.38190954773869346\n",
      "1000 0.001 0.49751243781094523\n",
      "1000 0.001 0.46715328467153283\n",
      "1000 0.0001 0.5341614906832298\n",
      "1000 0.0001 0.38848920863309355\n"
     ]
    }
   ],
   "source": [
    "Best_model=None\n",
    "Best_score=0\n",
    "Best_thresh = 0\n",
    "\n",
    "for C in [0.001,0.01,0.1,1,10,100,1000]:\n",
    "    for gamma in [10,1, 0.1, 0.01, 0.001, 0.0001]:\n",
    "        for kernel in ['rbf', 'poly']:\n",
    "            clf = SVC(C=C,gamma=gamma,kernel=kernel,probability=True)\n",
    "            clf.fit(X_train, y_train)\n",
    "            thresh, score = find_thresh_and_f1(clf, X_valid, y_valid)\n",
    "            print(C,gamma,score)\n",
    "            if score>Best_score:\n",
    "                Best_model=clf\n",
    "                Best_score= score\n",
    "                Best_thresh = thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5864661654135338"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm_smote = Best_model\n",
    "print(best_svm_smote)\n",
    "y_pred = Best_model.predict_proba(X_test)\n",
    "label = (y_pred[:,0] < Best_thresh).astype(np.int)\n",
    "f1_score(y_test,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25575\n",
       "1    23017\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test,final = prepareData(bank)\n",
    "columns = final.drop('y',axis=1).columns\n",
    "X_train,y_train = overSMOTE(X_train,y_train,0.9)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    17902\n",
      "0    17000\n",
      "Name: y, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    6367\n",
       "1     867\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = final.drop('y',axis=1).columns\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test,final = prepareData(bank)\n",
    "X_train, y_train = overSMOTE(X_train,y_train,0.7)\n",
    "X = concat(X_train,y_train,columns)\n",
    "X_train, y_train = resamp(X,17000) \n",
    "y_valid.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 gini auto 0.5168447000821693\n",
      "2 gini None 0.43467336683417085\n",
      "2 entropy auto 0.4915682967959527\n",
      "2 entropy None 0.4238957737527804\n",
      "3 gini auto 0.523972602739726\n",
      "3 gini None 0.4736556219445953\n",
      "3 entropy auto 0.5067479320853286\n",
      "3 entropy None 0.502844141069397\n",
      "4 gini auto 0.5541303232426885\n",
      "4 gini None 0.5039370078740157\n",
      "4 entropy auto 0.5384615384615385\n",
      "4 entropy None 0.5056648777579009\n",
      "5 gini auto 0.5554161438728565\n",
      "5 gini None 0.5328920148944973\n",
      "5 entropy auto 0.5450061652281135\n",
      "5 entropy None 0.54281098546042\n",
      "6 gini auto 0.5612196283944736\n",
      "6 gini None 0.5492227979274611\n",
      "6 entropy auto 0.5617224880382775\n",
      "6 entropy None 0.5421052631578946\n",
      "7 gini auto 0.5523448602558029\n",
      "7 gini None 0.5645320197044335\n",
      "7 entropy auto 0.5584905660377358\n",
      "7 entropy None 0.5651564689397478\n",
      "8 gini auto 0.5715648854961832\n",
      "8 gini None 0.5712967235809876\n",
      "8 entropy auto 0.5647756138865369\n",
      "8 entropy None 0.5740486015589179\n",
      "9 gini auto 0.5719714964370547\n",
      "9 gini None 0.5781625781625781\n",
      "9 entropy auto 0.5608108108108109\n",
      "9 entropy None 0.577373211963589\n",
      "10 gini auto 0.5745905267817619\n",
      "10 gini None 0.5857957490927942\n",
      "10 entropy auto 0.575152041702867\n",
      "10 entropy None 0.5864509605662286\n",
      "11 gini auto 0.5712885840274375\n",
      "11 gini None 0.5908372827804108\n",
      "11 entropy auto 0.5764802631578948\n",
      "11 entropy None 0.5959855892949047\n",
      "12 gini auto 0.5789473684210527\n",
      "12 gini None 0.6001013684744044\n",
      "12 entropy auto 0.5782033743730051\n",
      "12 entropy None 0.5993914807302232\n",
      "13 gini auto 0.5830633965756594\n",
      "13 gini None 0.5984329089128305\n",
      "13 entropy auto 0.577634011090573\n",
      "13 entropy None 0.6074766355140186\n",
      "14 gini auto 0.58844287604764\n",
      "14 gini None 0.6047619047619047\n",
      "14 entropy auto 0.5835721107927411\n",
      "14 entropy None 0.6144578313253012\n",
      "15 gini auto 0.5819337267362686\n",
      "15 gini None 0.6057692307692308\n",
      "15 entropy auto 0.5877587758775878\n",
      "15 entropy None 0.6168042739193784\n",
      "16 gini auto 0.5852534562211982\n",
      "16 gini None 0.6039649608114337\n",
      "16 entropy auto 0.5853658536585366\n",
      "16 entropy None 0.6204849084611578\n",
      "17 gini auto 0.58502119642016\n",
      "17 gini None 0.6025697828976517\n",
      "17 entropy auto 0.5841121495327103\n",
      "17 entropy None 0.6183816183816184\n",
      "18 gini auto 0.5886019590382903\n",
      "18 gini None 0.5988500663423264\n",
      "18 entropy auto 0.5864519185220275\n",
      "18 entropy None 0.6175580221997982\n",
      "19 gini auto 0.5923039454456893\n",
      "19 gini None 0.5988593155893537\n",
      "19 entropy auto 0.5918762088974855\n",
      "19 entropy None 0.6160896130346232\n"
     ]
    }
   ],
   "source": [
    "Best_model=None\n",
    "Best_score=0\n",
    "Best_thresh = 0\n",
    "for n in range(2,20):\n",
    "    for c in [\"gini\",\"entropy\"]:\n",
    "        for mf in [\"auto\",None]:\n",
    "            clf = RandomForestClassifier(max_depth=n, criterion=c, max_features=mf,n_jobs=2)\n",
    "            clf.fit(X_train, y_train)\n",
    "            thresh, score = find_thresh_and_f1(clf, X_valid, y_valid)\n",
    "            print(n, c, mf, score)\n",
    "            if score>Best_score:\n",
    "                Best_model=clf\n",
    "                Best_score= score\n",
    "                Best_thresh = thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best forest RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='entropy', max_depth=19, max_features=None,\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=2,\n",
      "                       oob_score=False, random_state=None, verbose=0,\n",
      "                       warm_start=False) f1 0.5953150242326333\n"
     ]
    }
   ],
   "source": [
    "# X_train, y_train = overSMOTE(X_train,y_train,0.7)\n",
    "# X = concat(X_train,y_train,columns)\n",
    "# X_train, y_train = resamp(X,17000) \n",
    "\n",
    "y_pred = Best_model.predict_proba(X_test)\n",
    "label = (y_pred[:,0] < Best_thresh).astype(np.int)\n",
    "f1_forest1 = f1_score(y_test,label)\n",
    "thresh_forest1 = Best_thresh\n",
    "best_forest1 = Best_model \n",
    "print(\"best forest\",best_forest1,'f1', f1_forest1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best forest RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='entropy', max_depth=19, max_features=None,\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=2,\n",
      "                       oob_score=False, random_state=None, verbose=0,\n",
      "                       warm_start=False) f1 0.5953150242326333\n"
     ]
    }
   ],
   "source": [
    "# columns = final.drop('y',axis=1).columns\n",
    "# X_train,y_train = overSMOTE(X_train,y_train,0.9)\n",
    "# y_train.value_counts()\n",
    "\n",
    "y_pred = Best_model.predict_proba(X_test)\n",
    "label = (y_pred[:,0] < Best_thresh).astype(np.int)\n",
    "f1_forest2 = f1_score(y_test,label)\n",
    "thresh_forest2 = Best_thresh\n",
    "best_forest2 = Best_model \n",
    "print(\"best forest\",best_forest1,'f1', f1_forest1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2 0.4538590604026846\n",
      "2 3 0.46098654708520176\n",
      "2 4 0.4655831739961759\n",
      "2 5 0.46357615894039733\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-100dcb14189d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'minkowski'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mleaf_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mleaf_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mthresh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_thresh_and_f1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mBest_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-3e64132265d1>\u001b[0m in \u001b[0;36mfind_thresh_and_f1\u001b[1;34m(clf, X_valid, y_valid)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mbest_thresh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mthresh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mthresh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programy\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programy\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    661\u001b[0m                 delayed_query(\n\u001b[0;32m    662\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[1;32m--> 663\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    664\u001b[0m             )\n\u001b[0;32m    665\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programy\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programy\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programy\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programy\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programy\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programy\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programy\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programy\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[1;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m     \"\"\"\n\u001b[1;32m--> 490\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Best_model=None\n",
    "Best_score=0\n",
    "Best_thresh = 0\n",
    "for p in [2]:\n",
    "    for leaf_size in range(1,50):\n",
    "        for k in range(2,20):\n",
    "            clf = KNeighborsClassifier(n_neighbors=k, p=p,metric='minkowski',leaf_size=leaf_size)\n",
    "            clf.fit(X_train, y_train)\n",
    "            thresh, score = find_thresh_and_f1(clf, X_valid, y_valid)\n",
    "            print(p,k,score)\n",
    "            if score>Best_score:\n",
    "                Best_model=clf\n",
    "                Best_score= score\n",
    "                Best_thresh = thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Best_model.predict_proba(X_test)\n",
    "label = (y_pred[:,0] < Best_thresh).astype(np.int)\n",
    "f1_score(y_test,label)\n",
    "best_knn_smote = Best_model\n",
    "print(Best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=19, p=1,\n",
      "                     weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "print(Best_knn_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get best results with this imbalanced data using Random Forest algorithm eith parameters\n",
    "\n",
    "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='entropy', max_depth=16, max_features=None,\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=2,\n",
    "                       oob_score=False, random_state=None, verbose=0,\n",
    "                       warm_start=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
