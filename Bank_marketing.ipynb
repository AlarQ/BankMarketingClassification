{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be (or not) subscribed.\n",
    "\n",
    "<b>The classification goal</b> - to predict if the client will subscribe a term deposit (variable y).\n",
    "\n",
    "Number of Instances: 45211 for bank-full.csv (4521 for bank.csv)\n",
    "Number of Attributes: 16 + output attribute.\n",
    "\n",
    "<b>Input variables</b>\n",
    "\n",
    "<b>bank client data</b>\n",
    "1 - age (numeric) 2 - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\", \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\") 3 - marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed) 4 - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\") 5 - default: has credit in default? (binary: \"yes\",\"no\") 6 - balance: average yearly balance, in euros (numeric) 7 - housing: has housing loan? (binary: \"yes\",\"no\") 8 - loan: has personal loan? (binary: \"yes\",\"no\")\n",
    "\n",
    "<b>related with the last contact of the current campaign</b>\n",
    "9 - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") 10 - day: last contact day of the month (numeric) 11 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\") 12 - duration: last contact duration, in seconds (numeric)\n",
    "\n",
    "<b>other attributes</b>\n",
    "13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact) 14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted) 15 - previous: number of contacts performed before this campaign and for this client (numeric) 16 - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\n",
    "\n",
    "<b>Output variable</b>\n",
    "17 - y - has the client subscribed a term deposit? (binary: \"yes\",\"no\")\n",
    "\n",
    "Missing Attribute Values: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age            77\n",
       "job            12\n",
       "marital         3\n",
       "education       4\n",
       "default         2\n",
       "balance      7168\n",
       "housing         2\n",
       "loan            2\n",
       "contact         3\n",
       "day            31\n",
       "month          12\n",
       "duration     1573\n",
       "campaign       48\n",
       "pdays         559\n",
       "previous       41\n",
       "poutcome        4\n",
       "y               2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank = pd.read_csv('bank-full.csv')\n",
    "bank = pd.DataFrame(bank)\n",
    "bank.isnull().sum()\n",
    "bank.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(bank):\n",
    "  #  print(\"****************************** General info ******************************\")\n",
    "    #print(bank.shape)\n",
    "    #print(bank.head())\n",
    "   # print(\"\\n>>> value counts of target variable:\\n\")\n",
    "    #print(bank['y'].value_counts())\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    bank['y'] = le.fit_transform(bank['y'])\n",
    "\n",
    "    #print(\"\\n>>> Data related to client\\n\")\n",
    "    client = bank.iloc[:,0:8]\n",
    "    labelencoder_X = LabelEncoder()\n",
    "    client['default']  = labelencoder_X.fit_transform(client['default']) \n",
    "    client['housing']  = labelencoder_X.fit_transform(client['housing']) \n",
    "    client['loan']     = labelencoder_X.fit_transform(client['loan']) \n",
    "    client = pd.get_dummies(client, drop_first=True)\n",
    "\n",
    "\n",
    "    #print(\"\\n>>> Data related to last contact\\n\")\n",
    "    last_cont = bank.iloc[:,8:12]\n",
    "    labelencoder_X = LabelEncoder()\n",
    "    last_cont['month']       = labelencoder_X.fit_transform(last_cont['month']) \n",
    "    #last_cont['day'] = labelencoder_X.fit_transform(last_cont['day']) \n",
    "    last_cont = pd.get_dummies(last_cont, drop_first=True)\n",
    "\n",
    "\n",
    "    #print(\"\\n>>> others features\\n\")\n",
    "    others = bank.iloc[:,12:16]\n",
    "    #others['poutcome'].replace(['unknown', 'failure', 'success','other'], [1,2,3,4], inplace  = True)\n",
    "    others = pd.get_dummies(others, drop_first=True)\n",
    "    #print(\"\\n>>> final form of data\\n\")\n",
    "    final= pd.concat([client, last_cont,others], axis = 1)\n",
    "    final.shape\n",
    "    final = pd.concat([final,bank['y']],axis = 1)\n",
    "    #print(final.head())\n",
    "\n",
    "    #split data\n",
    "    X=final.drop(\"y\",axis=1)\n",
    "    y = final['y']\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    #standarization\n",
    "    sc_X = StandardScaler()\n",
    "    X_train = sc_X.fit_transform(X_train)\n",
    "    X_test = sc_X.transform(X_test)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test, final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>...</th>\n",
       "      <th>duration</th>\n",
       "      <th>contact_telephone</th>\n",
       "      <th>contact_unknown</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>2143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1506</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  default  balance  housing  loan  job_blue-collar  job_entrepreneur  \\\n",
       "0   58        0     2143        1     0                0                 0   \n",
       "1   44        0       29        1     0                0                 0   \n",
       "2   33        0        2        1     1                0                 1   \n",
       "3   47        0     1506        1     0                1                 0   \n",
       "4   33        0        1        0     0                0                 0   \n",
       "\n",
       "   job_housemaid  job_management  job_retired  ...  duration  \\\n",
       "0              0               1            0  ...       261   \n",
       "1              0               0            0  ...       151   \n",
       "2              0               0            0  ...        76   \n",
       "3              0               0            0  ...        92   \n",
       "4              0               0            0  ...       198   \n",
       "\n",
       "   contact_telephone  contact_unknown  campaign  pdays  previous  \\\n",
       "0                  0                1         1     -1         0   \n",
       "1                  0                1         1     -1         0   \n",
       "2                  0                1         1     -1         0   \n",
       "3                  0                1         1     -1         0   \n",
       "4                  0                1         1     -1         0   \n",
       "\n",
       "   poutcome_other  poutcome_success  poutcome_unknown  y  \n",
       "0               0                 0                 1  0  \n",
       "1               0                 0                 1  0  \n",
       "2               0                 0                 1  0  \n",
       "3               0                 0                 1  0  \n",
       "4               0                 0                 1  0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test, final = prepareData(bank)\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.3322783549363608\n",
      "10 0.5118244164630351\n",
      "15 0.6746462288836544\n",
      "20 0.820215585695255\n",
      "25 0.934320116301499\n",
      "30 0.9929835288564259\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,7):\n",
    "    pca = PCA(n_components=i*5)\n",
    "    pca.fit(X_train)\n",
    "    print(i*5, pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_thresh_and_f1(clf, X_valid, y_valid):\n",
    "    best_f1=0\n",
    "    best_thresh=0\n",
    "    thresh = 0.05\n",
    "    prob = clf.predict_proba(X_valid)\n",
    "    while thresh < 1:\n",
    "        label = (prob[:,0] < thresh).astype(np.int)\n",
    "        f1 = f1_score(y_valid,label)\n",
    "#         print(f1)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thresh = thresh\n",
    "        thresh += 0.05\n",
    "    return best_thresh, best_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_model=None\n",
    "Best_score=0\n",
    "Best_thresh = 0\n",
    "for n in range(2,20):\n",
    "    for c in [\"gini\",\"entropy\"]:\n",
    "        for mf in [\"auto\",None]:\n",
    "            clf = RandomForestClassifier(max_depth=n, criterion=c, max_features=mf,n_jobs=2)\n",
    "            clf.fit(X_train, y_train)\n",
    "            thresh, score = find_thresh_and_f1(clf, X_valid, y_valid)\n",
    "          #  print(n, c, mf, score)\n",
    "            if score>Best_score:\n",
    "                Best_model=clf\n",
    "                Best_score= score\n",
    "                Best_thresh = thresh\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best forest RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='entropy', max_depth=16, max_features=None,\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=2,\n",
      "                       oob_score=False, random_state=None, verbose=0,\n",
      "                       warm_start=False) f1 0.6014652014652014\n"
     ]
    }
   ],
   "source": [
    "y_pred = Best_model.predict_proba(X_test)\n",
    "label = (y_pred[:,0] < Best_thresh).astype(np.int)\n",
    "f1_forest = f1_score(y_test,label)\n",
    "thresh_forest = Best_thresh\n",
    "best_forest = Best_model \n",
    "print(\"best forest\",best_forest,'f1', f1_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(estimator=best_forest, X=X_train, y=y_train, \n",
    "                                                        train_sizes=np.linspace(0.1, 1.0, 10), \n",
    "                                                        cv=10, n_jobs=1,scoring=\"f1\")\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1) \n",
    "train_std = np.std(train_scores, axis=1) \n",
    "test_mean = np.mean(test_scores, axis=1) \n",
    "test_std = np.std(test_scores, axis=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_sizes, train_mean,color='blue', marker='o', markersize=5, label='training accuracy')\n",
    "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std,alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, test_mean, color='green', linestyle='--', marker='s', markersize=5, label='validation accuracy')\n",
    "plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('f1_score')\n",
    "plt.legend(loc='lower right') \n",
    "plt.ylim([-0.8, 1.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_model=None\n",
    "Best_score=0\n",
    "Best_thresh = 0\n",
    "c=0.0001\n",
    "while c < 1000:\n",
    "        clf = LogisticRegression(C=c)\n",
    "        clf.fit(X_train, y_train)\n",
    "        thresh, score = find_thresh_and_f1(clf, X_valid, y_valid)\n",
    "        print(c,score)\n",
    "        if score>Best_score:\n",
    "            Best_model=clf\n",
    "            Best_score= score\n",
    "            Best_thresh = thresh\n",
    "        c *= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best logreg LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) f1 0.5302390998593529\n"
     ]
    }
   ],
   "source": [
    "y_pred = Best_model.predict_proba(X_test)\n",
    "label = (y_pred[:,0] < Best_thresh).astype(np.int)\n",
    "f1_logreg = f1_score(y_test,label)\n",
    "best_logreg = Best_model \n",
    "thresh_logreg= Best_thresh\n",
    "print(\"best logreg\",best_logreg,'f1', f1_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_model=None\n",
    "Best_score=0\n",
    "Best_thresh = 0\n",
    "for n in range(1,20):\n",
    "    for c in [\"gini\",\"entropy\"]:\n",
    "        for lr in [0.001,0.01, 0.1, 0.2, 0.5,1,10]:\n",
    "            tree = DecisionTreeClassifier(criterion=c, \n",
    "                              max_depth=n,\n",
    "                              random_state=0)\n",
    "            clf = AdaBoostClassifier(base_estimator=tree,\n",
    "                         n_estimators=100, \n",
    "                         learning_rate=lr,\n",
    "                         random_state=0)\n",
    "            clf.fit(X_train, y_train)\n",
    "            thresh, score = find_thresh_and_auc(clf, X_valid, y_valid)\n",
    "            print(n, c, lr, score)\n",
    "            if score>Best_score:\n",
    "                Best_model=clf\n",
    "                Best_score= score\n",
    "                Best_thresh = thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Best_model.predict_proba(X_test)\n",
    "label = (y_pred[:,0] < Best_thresh).astype(np.int)\n",
    "f1_adab = f1_score(y_test,label)\n",
    "best_adab = Best_model \n",
    "print(\"best adab\",best_adab,'f1', f1_adab)\n",
    "classification_report(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2561\n",
       "1     331\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_small = pd.read_csv('bank.csv')\n",
    "bank_small = pd.DataFrame(bank_small)\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test,final = prepareData(bank_small)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 98 candidates, totalling 490 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   57.4s\n",
      "[Parallel(n_jobs=4)]: Done 490 out of 490 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=True, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=4,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [100, 10, 1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf', 'poly']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.001,0.01,0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [100,10,1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf','poly']}  \n",
    "grid = GridSearchCV(SVC(probability=True), param_grid,n_jobs=4, refit = True, verbose = 3,scoring ='f1') \n",
    "grid.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'gamma': 1, 'kernel': 'poly'}\n",
      "SVC(C=0.01, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=1, kernel='poly',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(grid.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svm1 = grid.best_estimator_\n",
    "y_pred =best_svm1.predict(X_test)\n",
    "#label = (y_pred[:,0] < Best_thresh).astype(np.int)\n",
    "f1_svm1 = f1_score(y_test,y_pred)\n",
    "print(\"best svm\",best_svm1,'f1', f1_svm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.01, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=1, kernel='poly',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(C=0.01, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma=1, kernel='poly',\n",
    "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
    "    verbose=False)\n",
    "svm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best svm SVC(C=0.01, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=1, kernel='poly',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False) f1 0.4621893178212586\n"
     ]
    }
   ],
   "source": [
    "best_svm = svm\n",
    "y_pred =best_svm.predict(X_test)\n",
    "f1_svm = f1_score(y_test,y_pred)\n",
    "print(\"best svm\",best_svm,'f1', f1_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_model=None\n",
    "Best_score=0\n",
    "Best_thresh = 0\n",
    "for p in range(1,2):\n",
    "    for k in range(2,20):\n",
    "        clf = KNeighborsClassifier(n_neighbors=k, p=p,metric='minkowski')\n",
    "        clf.fit(X_train, y_train)\n",
    "        thresh, score = find_thresh_and_f1(clf, X_valid, y_valid)\n",
    "        #print(p,k,score)\n",
    "        if score>Best_score:\n",
    "            Best_model=clf\n",
    "            Best_score= score\n",
    "            Best_thresh = thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best KNN KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=1,\n",
      "                     weights='uniform') f1 0.5046869141357331\n"
     ]
    }
   ],
   "source": [
    "y_pred = Best_model.predict_proba(X_test)\n",
    "label = (y_pred[:,0] < Best_thresh).astype(np.int)\n",
    "f1_knn = f1_score(y_test,label)\n",
    "best_knn = Best_model \n",
    "print(\"best KNN\",best_knn,'f1', f1_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(150,150,150,100,50), max_iter=1000,activation = 'relu',solver='adam',random_state=1)\n",
    "mlp.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(max_iter=100)\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-2, cv=5,scoring='f1')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best parameters found:\\n', clf.best_params_)\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best adab MLPClassifier(activation='tanh', alpha=0.05, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(50, 50, 50), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False) f1 0.47584033613445376\n"
     ]
    }
   ],
   "source": [
    "best_adab =clf.best_estimator_\n",
    "y_pred = best_adab.predict(X_test)\n",
    "f1_nlp = f1_score(y_test,y_pred)\n",
    "best_nlp =clf.best_estimator_\n",
    "print(\"best adab\",best_nlp,'f1', f1_nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE, UNDERSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2561\n",
       "1     331\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_small = pd.read_csv('bank.csv')\n",
    "bank_small = pd.DataFrame(bank_small)\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test,final = prepareData(bank_small)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overSMOTE(X_train,y_train,samp_strat):\n",
    "    sm = SMOTE(sampling_strategy=samp_strat,k_neighbors=5,n_jobs=2)\n",
    "    X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "    y_train.value_counts()\n",
    "    return X_train,y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(X_train,y_train,columns):\n",
    "    df_y_train = pd.DataFrame(y_train,columns=['y'])\n",
    "    df_X_train = pd.DataFrame(data=X_train,columns=columns)\n",
    "    df_X_train.reset_index(drop=True, inplace=True)\n",
    "    df_y_train.reset_index(drop=True, inplace=True)\n",
    "    X= pd.concat([df_X_train, df_y_train], axis = 1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resamp(X,n_samples):\n",
    "    not_subscribed = X[X.y==0]\n",
    "    subscribed = X[X.y==1]\n",
    "\n",
    "    not_subscribed_undersampled = resample(not_subscribed,\n",
    "                              replace=False, \n",
    "                              n_samples=n_samples, \n",
    "                              random_state=1) \n",
    "    not_subscribed_undersampled.reset_index(drop=True, inplace=True)\n",
    "    subscribed.reset_index(drop=True, inplace=True)\n",
    "    undersampled = pd.concat([not_subscribed_undersampled,subscribed], axis = 0)\n",
    "    print(undersampled.y.value_counts())\n",
    "    y_train = undersampled.y\n",
    "    X_train = undersampled.drop('y', axis=1)\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2561\n",
       "1    2304\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,y_train = overSMOTE(X_train,y_train,0.9)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_model=None\n",
    "Best_score=0\n",
    "Best_thresh = 0\n",
    "\n",
    "for C in [0.001,0.01,0.1,1,10,100,1000]:\n",
    "    for gamma in [10,1, 0.1, 0.01, 0.001, 0.0001]:\n",
    "        for kernel in ['rbf', 'poly']:\n",
    "            clf = SVC(C=C,gamma=gamma,kernel=kernel,probability=True)\n",
    "            clf.fit(X_train, y_train)\n",
    "            thresh, score = find_thresh_and_f1(clf, X_valid, y_valid)\n",
    "            print(C,gamma,score)\n",
    "            if score>Best_score:\n",
    "                Best_model=clf\n",
    "                Best_score= score\n",
    "                Best_thresh = thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5864661654135338"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm_smote = Best_model\n",
    "print(best_svm_smote)\n",
    "y_pred = Best_model.predict_proba(X_test)\n",
    "label = (y_pred[:,0] < Best_thresh).astype(np.int)\n",
    "f1_score(y_test,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25575\n",
       "1    23017\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test,final = prepareData(bank)\n",
    "columns = final.drop('y',axis=1).columns\n",
    "X_train,y_train = overSMOTE(X_train,y_train,0.9)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    17902\n",
      "0    17000\n",
      "Name: y, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    6367\n",
       "1     867\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = final.drop('y',axis=1).columns\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test,final = prepareData(bank)\n",
    "X_train, y_train = overSMOTE(X_train,y_train,0.7)\n",
    "X = concat(X_train,y_train,columns)\n",
    "X_train, y_train = resamp(X,17000) \n",
    "y_valid.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_model=None\n",
    "Best_score=0\n",
    "Best_thresh = 0\n",
    "for n in range(2,20):\n",
    "    for c in [\"gini\",\"entropy\"]:\n",
    "        for mf in [\"auto\",None]:\n",
    "            clf = RandomForestClassifier(max_depth=n, criterion=c, max_features=mf,n_jobs=2)\n",
    "            clf.fit(X_train, y_train)\n",
    "            thresh, score = find_thresh_and_f1(clf, X_valid, y_valid)\n",
    "           # print(n, c, mf, score)\n",
    "            if score>Best_score:\n",
    "                Best_model=clf\n",
    "                Best_score= score\n",
    "                Best_thresh = thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best forest RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='entropy', max_depth=19, max_features=None,\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=2,\n",
      "                       oob_score=False, random_state=None, verbose=0,\n",
      "                       warm_start=False) f1 0.5953150242326333\n"
     ]
    }
   ],
   "source": [
    "# X_train, y_train = overSMOTE(X_train,y_train,0.7)\n",
    "# X = concat(X_train,y_train,columns)\n",
    "# X_train, y_train = resamp(X,17000) \n",
    "\n",
    "y_pred = Best_model.predict_proba(X_test)\n",
    "label = (y_pred[:,0] < Best_thresh).astype(np.int)\n",
    "f1_forest1 = f1_score(y_test,label)\n",
    "thresh_forest1 = Best_thresh\n",
    "best_forest1 = Best_model \n",
    "print(\"best forest\",best_forest1,'f1', f1_forest1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best forest RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='entropy', max_depth=19, max_features=None,\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=2,\n",
      "                       oob_score=False, random_state=None, verbose=0,\n",
      "                       warm_start=False) f1 0.5953150242326333\n"
     ]
    }
   ],
   "source": [
    "# columns = final.drop('y',axis=1).columns\n",
    "# X_train,y_train = overSMOTE(X_train,y_train,0.9)\n",
    "# y_train.value_counts()\n",
    "\n",
    "y_pred = Best_model.predict_proba(X_test)\n",
    "label = (y_pred[:,0] < Best_thresh).astype(np.int)\n",
    "f1_forest2 = f1_score(y_test,label)\n",
    "thresh_forest2 = Best_thresh\n",
    "best_forest2 = Best_model \n",
    "print(\"best forest\",best_forest1,'f1', f1_forest1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_model=None\n",
    "Best_score=0\n",
    "Best_thresh = 0\n",
    "for p in [2]:\n",
    "    for leaf_size in range(1,50):\n",
    "        for k in range(2,20):\n",
    "            clf = KNeighborsClassifier(n_neighbors=k, p=p,metric='minkowski',leaf_size=leaf_size)\n",
    "            clf.fit(X_train, y_train)\n",
    "            thresh, score = find_thresh_and_f1(clf, X_valid, y_valid)\n",
    "            print(p,k,score)\n",
    "            if score>Best_score:\n",
    "                Best_model=clf\n",
    "                Best_score= score\n",
    "                Best_thresh = thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Best_model.predict_proba(X_test)\n",
    "label = (y_pred[:,0] < Best_thresh).astype(np.int)\n",
    "f1_score(y_test,label)\n",
    "best_knn_smote = Best_model\n",
    "print(Best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=19, p=1,\n",
      "                     weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "print(Best_knn_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imbalanced data are hard to deal with. After trying undersampling and oversampling methods we get best results with this imbalanced data using Random Forest algorithm eith parameters\n",
    "\n",
    "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='entropy', max_depth=16, max_features=None,\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=2,\n",
    "                       oob_score=False, random_state=None, verbose=0,\n",
    "                       warm_start=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
